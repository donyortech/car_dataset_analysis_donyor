{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d8e2679",
   "metadata": {},
   "source": [
    "# Car Dataset Preprocessing and Analysis\n",
    "\n",
    "This notebook demonstrates a complete data preprocessing workflow for a car statistics dataset. It follows the structure requested: data loading, inspection, handling anomalies, filling missing values, deduplication, feature engineering, scaling, and visualizations. The notebook creates a synthetic `cars.csv` if you don't provide one, and saves a cleaned dataset at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a893c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sns.set_theme()\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61029365",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '\\mnt\\data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     32\u001b[39m df_synth.loc[np.random.choice(n,\u001b[32m50\u001b[39m), \u001b[33m'\u001b[39m\u001b[33mmileage\u001b[39m\u001b[33m'\u001b[39m] = np.nan\n\u001b[32m     33\u001b[39m df_synth = pd.concat([df_synth, df_synth.sample(\u001b[32m20\u001b[39m, random_state=\u001b[32m1\u001b[39m)], ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[43mdf_synth\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/mnt/data/cars.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mSynthetic dataset saved to /mnt/data/cars.csv, shape:\u001b[39m\u001b[33m'\u001b[39m, df_synth.shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:3986\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3975\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3977\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3978\u001b[39m     frame=df,\n\u001b[32m   3979\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3983\u001b[39m     decimal=decimal,\n\u001b[32m   3984\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3986\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3987\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3988\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3989\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3990\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3991\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3992\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3993\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3994\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3995\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3996\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3999\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4003\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m._save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:749\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    747\u001b[39m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[32m--> \u001b[39m\u001b[32m749\u001b[39m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m compression != \u001b[33m\"\u001b[39m\u001b[33mzstd\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:616\u001b[39m, in \u001b[36mcheck_parent_directory\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    614\u001b[39m parent = Path(path).parent\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent.is_dir():\n\u001b[32m--> \u001b[39m\u001b[32m616\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33mrf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot save file into a non-existent directory: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mOSError\u001b[39m: Cannot save file into a non-existent directory: '\\mnt\\data'"
     ]
    }
   ],
   "source": [
    "# Create a synthetic car dataset and save to 'cars.csv' (if you already have a file named cars.csv, you may overwrite or skip this cell)\n",
    "np.random.seed(42)\n",
    "n = 5000\n",
    "brands = ['toyota','bmw','kia','hyundai','ford','audi','mercedes','nissan','honda','volkswagen']\n",
    "models = ['model_'+str(i) for i in range(1,21)]\n",
    "years = np.random.randint(1995, 2025, size=n)\n",
    "mileages = np.abs((np.random.normal(loc=80000, scale=40000, size=n)).astype(int))\n",
    "mileages[np.random.choice(n, 10)] = np.random.randint(500000, 2000000, size=10)\n",
    "mileages[np.random.choice(n, 5)] *= -1\n",
    "engine_size = np.round(np.random.choice([1.2,1.4,1.6,1.8,2.0,2.5,3.0,4.0], size=n, p=[0.08,0.12,0.2,0.15,0.2,0.12,0.08,0.05]),2)\n",
    "fuel_type = np.random.choice(['Petrol','Diesel','petrol','Gasoline','electric','hybrid','diesel'], size=n, p=[0.45,0.18,0.1,0.1,0.05,0.08,0.04])\n",
    "horsepower = np.round(np.random.normal(loc=150, scale=60, size=n)).astype(object)\n",
    "hp_nan_idx = np.random.choice(n, 200, replace=False)\n",
    "for i in hp_nan_idx:\n",
    "    horsepower[i] = None\n",
    "price = np.round(np.abs(np.random.normal(loc=15000, scale=10000, size=n))).astype(int)\n",
    "price[np.random.choice(n, 8)] = np.random.randint(200000,1000000,size=8)\n",
    "transmission = np.random.choice(['Automatic','Manual','automatic','manual'], size=n, p=[0.6,0.35,0.03,0.02])\n",
    "brand = np.random.choice(brands, size=n, p=[0.15,0.1,0.1,0.1,0.1,0.08,0.07,0.1,0.08,0.12])\n",
    "model = np.random.choice(models, size=n)\n",
    "df_synth = pd.DataFrame({\n",
    "    'brand': brand,\n",
    "    'model': model,\n",
    "    'year': years,\n",
    "    'mileage': mileages,\n",
    "    'engine_size': engine_size,\n",
    "    'fuel_type': fuel_type,\n",
    "    'horsepower': horsepower,\n",
    "    'price': price,\n",
    "    'transmission': transmission\n",
    "})\n",
    "df_synth.loc[np.random.choice(n,50), 'mileage'] = np.nan\n",
    "df_synth = pd.concat([df_synth, df_synth.sample(20, random_state=1)], ignore_index=True)\n",
    "df_synth.to_csv('/mnt/data/cars.csv', index=False)\n",
    "print('Synthetic dataset saved to /mnt/data/cars.csv, shape:', df_synth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37188320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (change path if needed). If you have your own 'cars.csv', upload it to the environment and update the path.\n",
    "path = '/mnt/data/cars.csv'\n",
    "df = pd.read_csv(path)\n",
    "print('Loaded:', path)\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38531e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial descriptive statistics\n",
    "display(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cf4040d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 1) Year bounds: keep reasonable production years\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = \u001b[43mdf\u001b[49m[(df[\u001b[33m'\u001b[39m\u001b[33myear\u001b[39m\u001b[33m'\u001b[39m] >= \u001b[32m1970\u001b[39m) & (df[\u001b[33m'\u001b[39m\u001b[33myear\u001b[39m\u001b[33m'\u001b[39m] <= \u001b[32m2025\u001b[39m)].copy()\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# 2) Mileage: remove absurdly high values > 1_000_000, and convert negative mileages to abs (demonstration)\u001b[39;00m\n\u001b[32m      4\u001b[39m df.loc[df[\u001b[33m'\u001b[39m\u001b[33mmileage\u001b[39m\u001b[33m'\u001b[39m] < \u001b[32m0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmileage\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mmileage\u001b[39m\u001b[33m'\u001b[39m].abs()\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# 1) Year bounds: keep reasonable production years\n",
    "df = df[(df['year'] >= 1970) & (df['year'] <= 2025)].copy()\n",
    "# 2) Mileage: remove absurdly high values > 1_000_000, and convert negative mileages to abs (demonstration)\n",
    "df.loc[df['mileage'] < 0, 'mileage'] = df['mileage'].abs()\n",
    "df = df[df['mileage'] < 1_000_000]\n",
    "print('After basic anomaly filters, shape:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9dfd490",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m plt.figure(figsize=(\u001b[32m10\u001b[39m,\u001b[32m4\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m sns.boxplot(x=\u001b[43mdf\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mmileage\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      3\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mMileage - boxplot (after basic fixes)\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m plt.show()\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "sns.boxplot(x=df['mileage'])\n",
    "plt.title('Mileage - boxplot (after basic fixes)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dc5e239",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m text_cols = [\u001b[33m'\u001b[39m\u001b[33mbrand\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mfuel_type\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mtransmission\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m text_cols:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     df[c] = \u001b[43mdf\u001b[49m[c].astype(\u001b[38;5;28mstr\u001b[39m).str.lower().str.strip()\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Count and drop duplicates\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mDuplicates count before:\u001b[39m\u001b[33m'\u001b[39m, df.duplicated().sum())\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Normalize categorical text fields\n",
    "text_cols = ['brand','fuel_type','transmission','model']\n",
    "for c in text_cols:\n",
    "    df[c] = df[c].astype(str).str.lower().str.strip()\n",
    "\n",
    "# Count and drop duplicates\n",
    "print('Duplicates count before:', df.duplicated().sum())\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "print('Duplicates count after drop:', df.duplicated().sum(), ' shape:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86def02b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Fill numeric NaNs by group medians where sensible\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mmileage\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m.groupby(\u001b[33m'\u001b[39m\u001b[33mbrand\u001b[39m\u001b[33m'\u001b[39m)[\u001b[33m'\u001b[39m\u001b[33mmileage\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x.fillna(x.median()))\n\u001b[32m      3\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mhorsepower\u001b[39m\u001b[33m'\u001b[39m] = df.groupby(\u001b[33m'\u001b[39m\u001b[33mbrand\u001b[39m\u001b[33m'\u001b[39m)[\u001b[33m'\u001b[39m\u001b[33mhorsepower\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x.fillna(x.median()))\n\u001b[32m      4\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mmileage\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mmileage\u001b[39m\u001b[33m'\u001b[39m].fillna(df[\u001b[33m'\u001b[39m\u001b[33mmileage\u001b[39m\u001b[33m'\u001b[39m].median())\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Fill numeric NaNs by group medians where sensible\n",
    "df['mileage'] = df.groupby('brand')['mileage'].apply(lambda x: x.fillna(x.median()))\n",
    "df['horsepower'] = df.groupby('brand')['horsepower'].apply(lambda x: x.fillna(x.median()))\n",
    "df['mileage'] = df['mileage'].fillna(df['mileage'].median())\n",
    "df['horsepower'] = df['horsepower'].fillna(df['horsepower'].median())\n",
    "\n",
    "print('Any NaNs left?\\n', df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6027f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "CURRENT_YEAR = 2025\n",
    "df['car_age'] = CURRENT_YEAR - df['year']\n",
    "df['price_per_hp'] = df['price'] / (df['horsepower'].replace(0, np.nan))\n",
    "df['price_per_hp'] = df['price_per_hp'].fillna(df['price_per_hp'].median())\n",
    "\n",
    "df[['car_age','price_per_hp']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fbc9c3-1734-4a0b-8ec9-c07d581a6012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb633856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect price outliers per brand (drop above 99th percentile for each brand)\n",
    "def drop_brand_price_outliers(df_in):\n",
    "    to_drop_idx = []\n",
    "    for b, g in df_in.groupby('brand'):\n",
    "        up99 = g['price'].quantile(0.99)\n",
    "        mask = (g['price'] > up99)\n",
    "        to_drop_idx.extend(g[mask].index.tolist())\n",
    "    return df_in.drop(index=to_drop_idx)\n",
    "\n",
    "df = drop_brand_price_outliers(df)\n",
    "print('After dropping brand-wise price > 99th percentile, shape:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aea5554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling numeric columns\n",
    "scaler = MinMaxScaler()\n",
    "num_cols = ['mileage','engine_size','horsepower','price','car_age','price_per_hp']\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "df[num_cols].describe().loc[['min','max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85b155e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple visualizations\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.countplot(x='brand', data=df, order=df['brand'].value_counts().index[:15])\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Top brands count')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(df['car_age'], bins=30, kde=True)\n",
    "plt.title('Car age distribution')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x='mileage', y='price', data=df, hue='fuel_type', alpha=0.7)\n",
    "plt.title('Price vs mileage (scaled values)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85ca251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned dataset\n",
    "clean_path = '/mnt/data/cars_cleaned.csv'\n",
    "df.to_csv(clean_path, index=False)\n",
    "print('Cleaned dataset saved to', clean_path)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1afc91",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "- Use this cleaned dataset for clustering (KMeans), regression (price prediction), or classification tasks.\n",
    "- You can upload your real `cars.csv` and re-run the notebook: replace `/mnt/data/cars.csv` with your uploaded path.\n",
    "\n",
    "---\n",
    "Notebook generated automatically."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
